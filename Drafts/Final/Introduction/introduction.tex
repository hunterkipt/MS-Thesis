% This file is for the Introduction section of the Master's Thesis.
% This file will not compile on it's own. Will need to include it into a main file
% That uses the drexel thesis template.
\chapter{Introduction}

In recent years, due to the increasing ease by which an individual is able to alter or falsify digital image content, video recordings have increased in prevalence as evidence that events have occurred. The proliferation of smartphones has made video recording accessible to a large portion of the population. However, it has become increasingly apparent that video evidence is not foolproof. Falsified video content is increasingly being disseminated to the general populace, often from sources they trust. To combat this, research into digital media forensics has emerged over the past 15 years \cite{A}.

Digital media forensics seeks to provide information about digital media without the use of information that is not intrinsic to the piece of media in question. Specifically, digital media forensic techniques are formulated to work without the use of metadata or implanted watermarks to make a determination about the nature of digital media content. As such, the techniques instead process the multimedia content to extract fingerprints, which are specific signals left in media content by editing operations or the media capture process. These forensic techniques have become incredibly important in verifying the legitimacy of digital media content.

Research into digital media forensics has been developed to solve a wide variety of forensics problems \cite{A} \cite{B} \cite{D}. One well studied problem is that of source identification. Given a sample of digital media, can an investigator figure out the source of the content? For visual media, research has largely been focused on what device or camera model was used to capture the content. Image source identification research has not only been able to determine what model of camera captured an image \cite{imagesourceid, E, F, G, H, I, J, K, L, M}, but also what specific device \cite{prnu, N, O, P} has captured an image. Recent work has been conducted on determining both the source camera model of video content \cite{videosourceid} as well as the specific video device \cite{Q} \cite{R}.

Another significant problem studied by digital media forensics researchers is that of media forgery detection. Given a sample of digital media, can an investigator determine the authenticity of the content? Has the image or video undergone additional post-processing after it was captured, and does this post processing affect the perception of the content? There are many different editing operations that can be done on images, each of which introduces different fingerprints that can be detected. Detecting contrast enhancement \cite{contrastenhance, U, V}, resampling \cite{resampling, S, T}, double compression \cite{doubleJPEG, T, W, X}, and others \cite{lca, Y, Z, AA, BB, CC, DD, EE, FF} can help an investigator determine an image's processing history, and make a determination as to the authenticity of the content. Recently, editing and forgery detectors have been formulated using deep learning techniques as well \cite{imagesourceid}. 

Detecting forgery in video is a much more difficult task. As a video consists of multiple images, often of lower quality due to heavy compression, fingerprints are more difficult to extract. One particular video editing operation that has seen significant research is that of video frame deletion. Video frame deletion occurs when a frame or sequence of frames is removed from a video. To do this, a forger must decode the video, remove a frame or sequence of frames, then reencode the video. If frames are removed from the beginning of a video sequence, a forger can produce a video that has no discernible difference between a freshly captured video but can portray a significantly different message to a viewer. An example of this is in video of violent protests or police brutality. If there are inciting incidents to the violence, removing the context surrounding the events can make otherwise justified actions seem unreasonable.

To date, most techniques to detect video frame deletion were formulated to work on MPEG-2 encoded video\cite{wang} \cite{stamm}. The techniques largely rely on traces left by the video frame prediction process. Most video encoding standards define a procedure for predicting the image content in a frame from other frames in the video. This is known as inter-frame prediction. Inter-frame prediction is crucial to improving compression rates with minimal perceptible loss in visual quality. Modern video codecs such as H.264 or MPEG-4 contain more advanced techniques used in the frame prediction process. Thus, it is not clear whether the traces used to detect frame deletion on MPEG-2 are expressed in modern video. 

In this thesis, we show that indeed the advances in video encoding disrupt the traces left by frame deletion. Thus we propose a new technique for extracting the frame deletion traces for use on modern video codecs. In addition, we propose using added features and an autoregressive (AR) model to capture statistical variations between video captured from a variety of camera models and scene content. We propose using this expanded feature set with a Support Vector Machine (SVM) classifier for detection. As well, we formulate a series of experiments to evaluate the performance of detectors built using our proposed methodology and verify that they outperform the techniques proposed for MPEG-2 video.

The remainder of this thesis is organized as follows. In Chapter 2, we provide an overview of the background material necessary to understanding the problem of detecting video frame deletion, as well as our proposed methodology. In Chapter 3, we formulate the problem of video frame deletion detection as a classification problem and enumerate our assumptions. We explain the mathematical formulation behind frame deletion detection in MPEG-2, and use propose our methodology for detecting frame deletion in Chapter 4. We present the results of our experiments and evaluate the performance of our proposed techniques in Chapter 5. As well, we consider the effects of relaxing some of our assumptions and how that has bearing on future work. Finally, we conclude the thesis in Chapter 6.