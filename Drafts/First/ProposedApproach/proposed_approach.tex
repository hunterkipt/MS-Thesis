\chapter{Proposed Approach}

\section{Prediction Error Sequence Extraction}

In previous work on frame deletion detection in MPEG-2, the prediction error sequence was extracted directly from the video decoder using the DCT coefficients of the prediction error residuals located in the compressed video file. The prediction error was averaged over all macroblocks in a frame. This prediction error was then stored as a sequence. Due to the nature of the correlation between P-frame prediction errors across a single GOP, any prediction made across GOP boundaries would result in increased prediction error. Wang and Farid showed that for fixed GOP video, the increase in average prediction error is periodic with respect to the number of frames deleted from the video. Stamm's work expands the idea of the prediction error trace by introducing the formulation of the problem as detecting the prescence of a fingerprint signal $s(n)$. As H.264 uses variable GOP structures we will only be concerned with the model defined for variable GOP video. Stamm defines the model of $s(n)$ as

\begin{equation}
s(n) = \beta \mathds{1} \left( \Theta(n) = 0 \right).
\label{stammModel}
\end{equation}

where $\beta > 0$ is a constant and $\Theta(n)$ is a random variable distributed over the set $\{0, 1\}$. This model corresponds to modeling the fingerprint signal as randomly occurring sequence of discrete impulses with a magnitude of $\beta$. From this model he poses the detection of frame deletion as distinguishing between two hypotheses:

\begin{equation}
\begin{aligned}
  H_{0} : e(n) &= e_{1}(n). \\
  H_{1} : e(n) &= e_{2}(n) = e_{1}(n) + s(n)e_{1}(n).
\end{aligned}
\end{equation}

Thus, detection of frame deletion is detection of the presence of the modulated fingerprint signal $s(n)e_{1}(n)$. Given an unknown video, Stamm first makes an approximation of the unaltered P-frame prediction error sequence. To do this he uses a mediam filter with a filter width of 3.

\begin{equation}
\hat{e}(n) = \text{median}\{ e(n-1), e(n), e(n+1) \}.
\end{equation}

Thus, the relationship between the estimate and $e_{1}(n)$ is

\begin{equation}
e_{1}(n) = \hat{e}(n) + \epsilon(n).
\end{equation}

where $\epsilon(n)$ is a zero mean random variable representing estimation error.

Using the estimate of the unaltered P-frame prediction error sequence, Stamm calculates $\hat{s}(n)$, which is an estimate of the fingerprint signal modulated by the prediction error sequence as defined by

\begin{equation}
\hat{s}(n) = \text{max}(e(n) - \hat{e}(n), 0).
\end{equation}

The estimate of the fingerprint signal is floored at 0, as the model of the $s(n)$ dictates that it must be greater than or equal to 0. This estimate of the fingerprint signal can be used to build a detector. The decision function found by Stamm for variable GOP video is

\begin{equation}
\delta_{var} =
\begin{cases}
  H_{0} & \text{if } \frac{1}{N} \sum_{n=1}^{N} \vert \hat{s}(n) \vert < \tau_{var} \\
  H_{1} & \text{if } \frac{1}{N} \sum_{n=1}^{N} \vert \hat{s}(n) \vert \geq \tau_{var}
\end{cases}
\end{equation}

In MPEG-2, a P-frame is encoded by searching the previous anchor frame for the macroblock which incurs the least error. This means that the average prediction error for a single P-frame is only asssociated with the previous I or P-frame. H.264 expands the capabilities of its motion compensation and estimation system by allowing prediction from multiple previous frames (and subsequent frames in the case of B-frames). If the prediction error trace is extracted via the codec for H.264, the average prediction error associated with one frame is comprised of a linear combination of the average prediction error associated with motion vectors that map to the different anchor frames used in the motion estimation and compensation process. In H.264, the prediction error sequence $e(n)$ can be defined Thus, cross GOP predictions are smoothed out in such a way that it makes the fingerprint energy detector in Stamm's paper perform inadequately.

To test this, we collected 230 videos from a cell phone camera (the ASUS ZenFone 3 Laser), and generated an altered video with 15 frames removed from the beginning corresponding to each collected video. The encoding parameters were kept constant, and we fixed the GOP of the altered videos to that of the unaltered videos. In this particular case, the GOP structure was 30 frames in length, with 1 I-frame followed by 29 P-frames. We extracted the prediction error sequence directly from the codec, and measured the estimated fingerprint energy as described above.

\begin{figure}[tbp]%
  \centering
  \subfloat[MPEG-2 Detector on MPEG-2]{{\includegraphics[height=5cm]{ProposedApproach/old_method_roc_mpeg2.png}}}%
  \qquad
  \subfloat[MPEG-2 Detector on H.264]{{\includegraphics[height=5cm]{ProposedApproach/old_method_roc_h264.png}}}%
\caption{Comparison Between MPEG-2 Detection Methods used on MPEG-2 and H.264}%
\label{oldMethodCompare}%
\end{figure}


As shown in Fig. ~\ref{oldMethodCompare} the probability of detection using the methodology from MPEG-2 videos does not translate to H.264, particularly at low false alarm rates. This is due to a limitation in the model used by Stamm above in equation ~\ref{stammModel}. As it is possible to predict across multiple previous anchor frames in H.264, the contribution of the fingerprint signal is variable over time. This variation is also not regular, as scene content and motion determine how many cross GOP predictions are present in each P-frame. Thus we propose the updated model for the fingerprint signal as

\begin{equation}
s(n) = \beta(n) \mathds{1} \left( \Theta(n) = 0 \right).
\end{equation}

where $\beta(n)$ is now a random variable that takes values in $\R_{\geq 0}$. Thus, we propose the following methodology for extracting the prediction error sequence in H.264.

\subsection{Proposed Prediction Error Sequence Extractor for H.264}

The goal of the proposed extraction algorithm is to maximize the probability that should frame deletion exist, a given measurement of the prediction error comes from a cross-GOP prediction. To this end, instead of directly measuring the prediction error from the DCT coefficients from the decoder, we decode the frame of interest and store the motion vectors associated with said frame. For each macroblock in the current frame, we use its associated motion vector to find the x and y coordinates defining the source macroblock which provides the least error mapping from a previous anchor frame. Then for a previous anchor frame, we subtract the pixels in the source macroblock from the destination macroblock in the current frame. This leaves us with a prediction error residual associated with the macroblock. We then calculate the average absolute value of this residual.

%TODO Insert Figure Showing Identification of Macroblocks in multiple previous frames

We repeat this process for each of D previous anchor frames. Then we store these prediction error values in a matrix $M$, where each row of the matrix corresponds to the errors associated with a single motion vector, and the columns are the errors associated with each of the previous anchor frames.

After obtaining the $M$ matrix for the current frame, we create the matrix $\tilde{M}$ defined like so:

\begin{equation}
  \tilde{M}_{i, j} = \mathds{1} \left(j = \argmin_{l} \left( M_{i, l} \right) \right) * M_{i, j}
\end{equation}

Thus $\tilde{M}$ is a copy of $M$ where the non-zero entries in each row correspond to the minimum average error associated with the macroblock and all other elements are zero. Effectively, the column index of the non-zero entry is an estimation of which previous frame the motion vector associated with the macroblock maps to in the decoding process.

Further processing is done on $\tilde{M}$ to output only a single prediction error value. First, $\tilde{M}$ is reduced into a vector $P$, such that:

\begin{equation}
  P_{j} = \frac{1}{N_{j}} \sum_{i}{\tilde{M}_{i,j}}
\end{equation}

Where $N_{j}$ is the number of non-zero elements in the $j^{th}$ column of $\tilde{M}$. Then, the reported prediction error $e$ is set as the maximum value of $P$. This entire process is repeated for every P frame in the video. This method of error extraction estimates which previous anchor frame contributes the maximum error per macroblock to the overall prediction error residual obtained by the codec for a given P frame. Since prediction across GOP boundaries results in spikes in the prediction error, the anchor frame that contributes the most error is most likely to be from a different original GOP. In this manner, we obtain a trace that is resilient to advances made in the motion compensation and estimation process in modern codecs as well as robust to variable frame rates and dynamic GOP structures.

\section{Proposed Detection Algorithm}

In addition to the new methods for prediction error extraction, we propose an expanded detection algorithm to better capture the statistical differences between videos. In fact, depending on scene content, video capture settings, and the amount of motion captured in a single recording, the prediction error sequence and fingerprint signal exhibit different structural behavior. This is true even for videos captured from a single camera model. Figure ~\ref{seqCompare} shows this clearly. The two videos were captured from an LG Nexus 5X using the high quality 1080p capture mode. Both videos were shot using similar scene content, but the amount of motion in each video is different. The first video was shot with hight motion, while the second video was comparatively low motion. The top row shows the different prediction error sequences, while the bottom row shows the different estimated fingerprint signals.

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.9\linewidth]{ProposedApproach/perror_seq_comparisons.png}}
\caption{Comparison Between Prediction Error Sequences and Fingerprint Signals from two Similar Videos}
\label{seqCompare}
\end{figure}

Thus there is a need to construct a parametric model of the fingerprint signal and the prediction error sequence to capture these statistical variations. We propose constructing an autoregressive (AR) model of both the fingerprint signal and the prediction error sequence. Over the time period of one GOP it can be said that the signals are mostly stationary. The parameters of the AR models are added to a feature vector along with the fingerprint energy described above. In order to capture the degree to which this is true, the error variance of each AR model is also included. In addition, some basic statistical features are included to scale the overall decision surface. We propose including the mean and variance of both the prediction error sequence and fingerprint signal to the feature vector as well.

Note that after creating a feature vector for each video, the feature vector is quite large. It is inadvisable to create a probabilistic model of the feature vector for classification. Instead, we propose using a discriminative function to map an incoming feature vector directly to the set of natural videos or the set of videos altered by frame deletion. As such, we propose using a Support Vector Machine (SVM) classifier with a Radial Basis Kernel function for classification.